{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deeply refered on  \n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring the Fields\n",
    "- Torchtext uses the method of declaring data during import.\n",
    "     - Declare what format the data will have, and torchtext will load the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "def tokenizer(text):\n",
    "    token = okt.nouns(text)\n",
    "    if len(token) < max_length:\n",
    "        for i in range(0, max_length - len(token)):\n",
    "            token.append('<PAD>')\n",
    "    else : \n",
    "        token = token[:max_length]\n",
    "    return token\n",
    "\n",
    "# If it is shorter than max_length, add the pad token, and if it is long, cut it to max_length.\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize=tokenizer,use_vocab=True) \n",
    "LABEL = Field(sequential=False,unk_token=None, use_vocab=True,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Dataset\n",
    "- The fields object contains a declaration of how to import the raw data.\n",
    "- Declare where and what data to fetch through the TabularDataset object.\n",
    "- The object created through the source code below is in the form of a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 34s, sys: 7.08 s, total: 9min 41s\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "datafields = [(\"X\", TEXT), (\"y\", LABEL)]\n",
    "\n",
    "train_data,test_data = TabularDataset.splits(\n",
    "                            path=\".\", \n",
    "                            train='train_df.csv',\n",
    "                            test='test_df.csv',\n",
    "                            format='csv',\n",
    "                            skip_header=True,\n",
    "                            fields=datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data);LABEL.build_vocab(train_data)\n",
    "TEXT.build_vocab(test_data);LABEL.build_vocab(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- through TabularDatset, tokenizing, but the word_to_integar process has not been done yet.\n",
    "- In our case, word_to_integar converting is required for the TEXT part for train and text datasets.\n",
    "- You can convert by using the code `TEXT.build_vocab (trn)`.\n",
    "- The above operation will create torchtext for all elements in all training sets. Torchtext has a class called Vocab that handles vocabulary. The Vocab class maps the word and id to the stoi attribute and the itos attribute to reverse mappings.\n",
    "- stoi: word_to_idx default dictionary\n",
    "- itos: word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "train_iter, test_iter = BucketIterator.splits(datasets=(train_data,test_data),\n",
    "                                            batch_sizes=(BATCH_SIZE,BATCH_SIZE),  \n",
    "                                            device=device,\n",
    "                                            repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) : \n",
    "    \n",
    "    def __init__(self,VOCAB_SIZE , EMBED_SIZE , HID_SIZE , DROPOUT ,KERNEL_SIZE , NUM_FILTER , N_CLASS ) : \n",
    "        super(CNN, self).__init__()\n",
    "        self.vocab_size = VOCAB_SIZE # whole vocab we use.\n",
    "        self.embed_size = EMBED_SIZE # Volumn of Embedding dimension this is hyperparameter.\n",
    "        self.hid_size = HID_SIZE # Volumn of Hidden layer dimension this is also hyperparameter.\n",
    "        self.dropout = DROPOUT # probability of occurence of dropout.\n",
    "        if type(KERNEL_SIZE) !=list :\n",
    "            self.kernel_size = list(KERNEL_SIZE) # size of kernel, we can assign kernel_size as type of list.\n",
    "        else : self.kernel_size = KERNEL_SIZE # longer size, more complex.\n",
    "        self.num_filter = NUM_FILTER # parameter how many kernel is. the larger more complex.\n",
    "        self.num_class = N_CLASS # argument about output_dimension, this is 1 becuz we gonna use sigmoid below.\n",
    "#         self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.device = 'cpu'\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings = self.vocab_size,\n",
    "            embedding_dim = self.embed_size,\n",
    "            padding_idx = 1) \n",
    "\n",
    "        # padding_idx : we ignore pad token during training.\n",
    "        # embedding vector's dimension : vocab_size * embed_size , similar with LOOKUP TABLE.\n",
    "        \n",
    "        self.convs = nn.ModuleList([(nn.Conv2d(in_channels = 1,out_channels = self.num_filter,\\\n",
    "        kernel_size = (kernel,self.embed_size))) for kernel in self.kernel_size])\n",
    "        # in_channels : in field of computer_vision, the user used to use more than 1, but in nlp, 1 in in_channels in more common.\n",
    "        # out_channels : we might catch more feature if we use larger out_channels potentially. so it's on your decision.\n",
    "        # kernel_size : size of kernel\n",
    "        \n",
    "        self.fully_connect = nn.Sequential(\n",
    "        nn.Linear(self.num_filter * len(self.kernel_size),self.hid_size),nn.ReLU(),\n",
    "        nn.Dropout(self.dropout),nn.Linear(self.hid_size , self.num_class),\n",
    "        )\n",
    "        \n",
    "        # 1. nn.Linear: concatenate num_filter * len (kernel_size) multiply a dimensional vector by a hidden layer.\n",
    "        # 2. nn.ReLU: To ensure non-linearity, insert the activation function Relu.\n",
    "        # 3. nn.Dropout: applies dropout to self.dropout probability.\n",
    "        # 4. nn.Linear: Match the final output with n-class classification and apply softmax or sigmoid etc.\n",
    "    \n",
    "    def forward(self,x) : \n",
    "        # x's dimension : [max_length, batch_size], max_length gonna be 30, becuz of tokenizer func(we made it at first).\n",
    "        if len(x.shape) == 1 :\n",
    "            x.unsqueeze_(0) \n",
    "        # [1, max_length, batch_size] The reason for squeezing 1 dim in dimension 0 is for embedding operations together.        \n",
    "        \n",
    "        embed = self.embedding(x) #[max_length, batch_size, embedding_dim]\n",
    "        embed = embed.unsqueeze(1) # [max_length, 1, batch_size, embedding_dim], for convolution.\n",
    "        embed = embed.permute(2,1,0,3)\n",
    "        # [batch_size, 1 , max_length , embedding_dim]\n",
    "        # You can think of a rectangle as batch_size. Since the depth of the kernel does not exist,\n",
    "        # Also put this information in unschEzE_ because you previously assigned this information to in_channels.\n",
    "        \n",
    "        \n",
    "        convolution = [conv(embed).squeeze(3) for conv in self.convs]\n",
    "        # [batch_size, num_filter, dimension after convolution(stride 값에 따라 변화할 수 있습니다!)]\n",
    "        \n",
    "        # Turning the convolution on nlp will result in 1 because the column size (length) of feature_map is equal to the embedding dimension.\n",
    "        # dimension of embedding dimension Since the index was 3, it squeezes the third index.\n",
    "        # Also, the second index, which had a length of max_length, changed due to the kernel size. This value will vary depending on the stride size.\n",
    "        # Rather than having a rectangle of batch_size, the vector has num_filter,\n",
    "        # The reason that such vectors 'vectors' are vectors is that after the convolution,\n",
    "        # Depending on the num_kernels parameter, there are several such vectors. The vectors in a dataset have the same dimensions, but the value of the kernel\n",
    "        # Note that the values of the elements of the vector are different. The words are longer, but the vectors are equal to num_kernels.)\n",
    "        # It seems better to think that these datasets are batch_size, because they are going to be a bunch at a time.\n",
    "        \n",
    "        \n",
    "        pooled = [F.max_pool1d(conv,(conv.size(2))).squeeze(2) for conv in convolution]\n",
    "        # [batch_size, num_filter]\n",
    "        # max_polling applies to the same filter with the same kernel size.\n",
    "        # So when we do pooling, the second parameter is conv.size (2), which is the length of the vector.\n",
    "        # Thus, only the max value of the vector value is extracted, and through squeeze, one vector becomes one scalar. That is, it becomes one-dimensional.\n",
    "        \n",
    "        dropout = [F.dropout(pool,self.dropout) for pool in pooled]\n",
    "        # The second argument, dropout, is a probability value, dropout% dropout% of hidden neurons whenever the epoch changes.\n",
    "        # This is a process that is a must for complex models with a large number of parameters, such as CNN.\n",
    "        \n",
    "        concatenate = torch.cat(dropout, dim = 1) \n",
    "        # [batch_size, num_filter * num_kernel]\n",
    "        #concatenate and return NN. Concat the kernel. So, one dataset has one long vector.\n",
    "        # It looks like an end, but you have to add nonlinearity, and you have to convert the output_dimension to a linear transform.\n",
    "        \n",
    "        logit = self.fully_connect(concatenate)\n",
    "        # NN is the process of putting in layer. Put it in linear layer according to the dimension of concat,\n",
    "        # Put in relu activation function for nonlinearity, then dropout\n",
    "        # The last value is a vector with the same num_of_class.\n",
    "        # if  binary classfication is a vector of length 2\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fit() : \n",
    "    \n",
    "    def __init__(self, model, train_iter, test_iter, epoch = 5) : \n",
    "        self.optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "        self.train_iter = train_iter\n",
    "        self.test_iter = test_iter\n",
    "        self.epoch = epoch\n",
    "        \n",
    "    def binary_accuracy(self, preds, y):\n",
    "        \"\"\"\n",
    "        Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "        \"\"\"\n",
    "\n",
    "        rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "        # In model, since we are fully connecting, we put sigmoid on it, and we do rounding.\n",
    "        correct = (rounded_preds == y).float() # If they are the same, they are 1\n",
    "        acc = correct.sum()/len(correct) # In one batch, the ratio is the ratio, or accuracy!\n",
    "        return acc\n",
    "    \n",
    "    def train(self, model, iterator):\n",
    "    \n",
    "        epoch_loss = 0 # loss per epoch\n",
    "        epoch_acc = 0 # accuracy per epoch\n",
    "\n",
    "        model.train()\n",
    "        for batch in iterator:\n",
    "            if batch.X.size(0) == 0 : continue #If there is no data, continue. It does not matter because you applied padding manually.\n",
    "            self.optimizer.zero_grad() # we should initialize manually gradient of optimizer in pytorch.\n",
    "\n",
    "            predictions = model(batch.X).squeeze(1) # becuz the size of fc from model is [batch_size, num_layer].            \n",
    "            loss = self.criterion(predictions, batch.y) # calculating the loss \n",
    "\n",
    "            acc = self.binary_accuracy(predictions, batch.y) # return the accracuy in form of ratio\n",
    "\n",
    "            loss.backward() # back propagation\n",
    "\n",
    "            self.optimizer.step() # update the SGD\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "    \n",
    "    def evaluate(self, model, iterator):\n",
    "    \n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        model.eval() # stop the every change in gradient of model\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for batch in iterator:\n",
    "                if batch.X.size(0) == 0 : continue\n",
    "                predictions = model(batch.X).squeeze(1)\n",
    "                loss = self.criterion(predictions, batch.y)\n",
    "\n",
    "                acc = self.binary_accuracy(predictions, batch.y)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc.item()\n",
    "\n",
    "        return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "    \n",
    "    def fit_by_iterate(self) : \n",
    "        \n",
    "        for epoch in range(self.epoch+1):\n",
    "            print('epoch : ',epoch+1,end='\\r')\n",
    "            train_loss, train_acc = self.train(self.model, self.train_iter)\n",
    "\n",
    "        valid_loss, valid_acc = self.evaluate(self.model, self.test_iter)\n",
    "        print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(23044, 256, padding_idx=1)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 4, kernel_size=(2, 256), stride=(1, 1))\n",
       "    (1): Conv2d(1, 4, kernel_size=(3, 256), stride=(1, 1))\n",
       "    (2): Conv2d(1, 4, kernel_size=(4, 256), stride=(1, 1))\n",
       "    (3): Conv2d(1, 4, kernel_size=(5, 256), stride=(1, 1))\n",
       "  )\n",
       "  (fully_connect): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBED_SIZE = 256\n",
    "HID_SIZE = 128\n",
    "DROPOUT = 0.5\n",
    "KERNEL_SIZE = [2,3,4,5]\n",
    "NUM_FILTER = 4\n",
    "N_CLASS = 1\n",
    "\n",
    "model = CNN(VOCAB_SIZE, EMBED_SIZE, HID_SIZE, DROPOUT, KERNEL_SIZE, NUM_FILTER, N_CLASS)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_process = fit(model,train_iter,test_iter,epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 05 | Train Loss: 0.639 | Train Acc: 62.87% | Val. Loss: 0.628 | Val. Acc: 64.05% |\n"
     ]
    }
   ],
   "source": [
    "fitting_process.fit_by_iterate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
