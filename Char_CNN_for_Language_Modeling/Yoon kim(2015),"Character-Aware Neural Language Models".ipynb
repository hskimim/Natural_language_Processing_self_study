{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 해당 노트북은 \"Character-Aware Neural Language Models\" 논문을 기반으로 합니다.\n",
    "- https://github.com/FengZiYjun/CharLM/blob/master/model.py 사이트를 참고하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring the Fields\n",
    "- Torchtext 는 데이터를 가져오는 과정에서 선언하는 방식을 사용합니다.\n",
    "    - 데이터가 어떤 형식을 지닐 것인지에 대한 것에 대해 선언을 해주고 이에 따라 torchtext 는 데이터를 로딩합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Dataset\n",
    "- fields 객체는 raw data 를 어떻게 가져올 지에 대한 선언이 담겨있습니다.\n",
    "- TabularDataset 객체를 통해서, 어디서, 어떤 데이터를 가져올 지에 대해 선언을 해줍니다.\n",
    "- 아래의 소스코드를 통해 형성된 객체는 generator 의 형태를 띕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up fields\n",
    "TEXT = data.Field(sequential=True, lower=True)\n",
    "LABEL = data.Field(sequential=False)\n",
    "\n",
    "# make splits for data\n",
    "train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "# build the vocabulary\n",
    "TEXT.build_vocab(train);TEXT.build_vocab(test)\n",
    "LABEL.build_vocab(train);LABEL.build_vocab(test)\n",
    "\n",
    "# make iterator for splits\n",
    "train_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, test), batch_size=3, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TabularDatset 을 통해서, tokenizing 까지는 되었지만, word_to_integar process는 아직 이뤄지지 않았습니다. \n",
    "- 우리의 경우, train , text 데이터 셋에 대해서 TEXT 부분에 대해서, word_to_integar converting이 필요합니다.\n",
    "- `TEXT.build_vocab(trn)` 이라는 코드를 통해, converting이 가능합니다.\n",
    "- 위의 연산은 모든 training set에 있는 모든 엘리먼트들을 torchtext로 만들어줍니다. Torchtext는 vocabulary를 핸들링하는 Vocab이라는 클래스를 가지고 있습니다. Vocab클래스는 word와 id를 stoi attribute에서 mapping 시켜주고, itos attribute에서는 reverse mapping시켜줍니다.\n",
    "- stoi : word_to_idx default dictionary \n",
    "- itos : word list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word dictionary를 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx_dict = TEXT.vocab.stoi\n",
    "idx_to_word_dict = {val:idx for idx,val in word_to_idx_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "character dictionary를 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(word_to_idx_dict.keys())[3:]\n",
    "char_dict = {}\n",
    "char_dict['<unk>'] = 0\n",
    "char_dict['<pad>'] = 1\n",
    "count = 1\n",
    "\n",
    "for word in word_list : \n",
    "    for char in word : \n",
    "        if char not in char_dict.keys() :\n",
    "            count += 1\n",
    "            char_dict[char] = count\n",
    "char_dict['<unk>'] = 0\n",
    "char_dict['<pad>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([427, 3])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "batch.text.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterIndex_for_SINGLE() : \n",
    "    \n",
    "    def __init__(self,idx_to_word_dict,char_dict,max_length=10,batch_size=3) :\n",
    "    \n",
    "        self.batch_size = batch_size\n",
    "        self.idx_to_word_dict = idx_to_word_dict\n",
    "        self.char_dict = char_dict\n",
    "        self.max_length = max_length\n",
    "    def return_char_idx(self,text) : \n",
    "\n",
    "        inputs_ = []\n",
    "    \n",
    "        for idx1 in range(batch_size) : \n",
    "            inputs_.append([char_dict[i] for i in idx_to_word_dict[text[idx1].item()]])\n",
    "        \n",
    "        for idx,val in enumerate(inputs_) : \n",
    "            if len(val) <= self.max_length :\n",
    "                inputs_[idx] = val + [1]*(self.max_length - len(val))\n",
    "            else : \n",
    "                inputs_[idx] = val[:self.max_length]\n",
    "        \n",
    "        t = torch.tensor(inputs_)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_idx = CharacterIndex_for_SINGLE(idx_to_word_dict,char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 25, 19, 20,  1,  1,  1,  1,  1,  1],\n",
       "        [27, 15,  8, 18,  2, 22,  1,  1,  1,  1],\n",
       "        [ 8,  1,  1,  1,  1,  1,  1,  1,  1,  1]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_idx.return_char_idx(batch.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Highway(nn.Module):\n",
    "    \"\"\"Highway network\"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        super(Highway, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, input_size, bias=True)\n",
    "        self.fc2 = nn.Linear(input_size, input_size, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return torch.mul(x, F.relu(self.fc2(x))) + torch.mul(1-x, x)\n",
    "\n",
    "class Char_CNN_for_SINGLE(nn.Module) : \n",
    "    \n",
    "    def __init__(self,word_dict,character_dict,idx_to_word_dict,char_embed_size,lstm_hidden_size,\\\n",
    "                 kernel_size,num_filter,dropout,num_layers) : \n",
    "        \n",
    "        super(Char_CNN_for_SINGLE, self).__init__()\n",
    "        \n",
    "        self.word_vocab_size = len(word_dict) \n",
    "        self.char_vocab_size = len(character_dict)\n",
    "        self.idx_to_word_dict = idx_to_word_dict\n",
    "        self.char_embed_size = char_embed_size \n",
    "        self.lstm_hidden_size = lstm_hidden_size \n",
    "        self.dropout = dropout \n",
    "        self.char_to_idx = CharacterIndex_for_SINGLE(idx_to_word_dict,character_dict)\n",
    "        \n",
    "        if type(kernel_size) !=list :\n",
    "            self.kernel_size = list(kernel_size) # kernel의 사이즈로, 여러개의 kernel_size를 리스트 형태로 넣어줄 수 있습니다.\n",
    "        else : self.kernel_size = kernel_size # 많을 수록 complex해집니다.\n",
    "            \n",
    "        self.num_filter = num_filter # 각각의 kernel 이 몇 개씩 있는지에 대한 파라미터입니다. 많을 수록 complex해집니다.\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings = self.char_vocab_size,\n",
    "            embedding_dim = char_embed_size,\n",
    "            padding_idx = 1) \n",
    "        \n",
    "        self.convs = nn.ModuleList([(nn.Conv2d(in_channels = 1,out_channels = self.num_filter,\\\n",
    "        kernel_size = (kernel,self.char_embed_size))) for kernel in self.kernel_size])\n",
    "    \n",
    "        self.highway = Highway(len(kernel_size)*num_filter)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=len(kernel_size)*num_filter, \n",
    "                hidden_size=lstm_hidden_size, \n",
    "                num_layers=num_layers,\n",
    "                dropout=dropout,\n",
    "                batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(lstm_hidden_size,len(self.idx_to_word_dict))\n",
    "        \n",
    "    def forward(self,x,hidden) : \n",
    "                \n",
    "        # x : [batch_size]\n",
    "        char_x = self.char_to_idx.return_char_idx(x) # char_idx : [batch_size, word_length]\n",
    "        \n",
    "        (batch_size,word_length) = char_x.size()\n",
    "        \n",
    "        embed = self.embedding(char_x) # embed : [batch_size,word_length, embed_dim]\n",
    "        embed = embed.unsqueeze(1) # embed : [batch_size*sent_length,1,word_length, embed_dim]\n",
    "        \n",
    "        convolution = [conv(embed).squeeze(3) for conv in self.convs]\n",
    "#         [torch.Size([batch_size, num_filter, filter_width+embed_dim-1])\n",
    "\n",
    "        pooled = [F.max_pool1d(conv,(conv.size(2))).squeeze(2) for conv in convolution]\n",
    "#         [torch.Size([batch_size, num_filter])\n",
    "\n",
    "        cat_mat = torch.cat(pooled,dim=1)\n",
    "#         [torch.Size([batch_size, num_filter * len(kernel_size)])\n",
    "\n",
    "        highway_net = self.highway(cat_mat)\n",
    "#         [torch.Size([batch_size, num_filter * len(kernel_size)])\n",
    "\n",
    "        outputs,hidden = self.lstm(highway_net.unsqueeze(1),hidden)\n",
    "#       [batch_size, 1, lstm_hidden_size]\n",
    "#       [num_layer, batch_size, lstm_hidden_size]\n",
    "        fc_mat = outputs.squeeze(1)\n",
    "#       [batch_size, lstm_hidden_size]\n",
    "        return self.fc(fc_mat),hidden\n",
    "#       self.fc(fc_mat) : [batch_size,char_vocab_size]\n",
    "#       hidden : [num_layer, batch_size, char_hidden_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Char_CNN_for_SINGLE(\n",
       "  (embedding): Embedding(147, 15, padding_idx=1)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 25, kernel_size=(1, 15), stride=(1, 1))\n",
       "    (1): Conv2d(1, 25, kernel_size=(2, 15), stride=(1, 1))\n",
       "    (2): Conv2d(1, 25, kernel_size=(3, 15), stride=(1, 1))\n",
       "    (3): Conv2d(1, 25, kernel_size=(4, 15), stride=(1, 1))\n",
       "  )\n",
       "  (highway): Highway(\n",
       "    (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  )\n",
       "  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=256, out_features=247632, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = word_to_idx_dict\n",
    "character_dict = char_dict\n",
    "idx_to_word_dict = idx_to_word_dict\n",
    "char_embed_size = 15\n",
    "lstm_hidden_size = 256\n",
    "kernel_size = [1, 2, 3, 4]\n",
    "num_filter = 25\n",
    "dropout = 0.5\n",
    "num_layers = 2\n",
    "\n",
    "model = \\\n",
    "Char_CNN_for_SINGLE(word_to_idx_dict,char_dict,idx_to_word_dict\\\n",
    "         ,char_embed_size,lstm_hidden_size,kernel_size,num_filter,dropout,num_layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 247632])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "\n",
    "hidden = torch.zeros(num_layers,batch_size,lstm_hidden_size)\n",
    "cell = torch.zeros(num_layers,batch_size,lstm_hidden_size)\n",
    "hiddens = (hidden,cell)\n",
    "\n",
    "outputs,hidden = model(batch.text[0],hiddens)\n",
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Char_LM(nn.Module):\n",
    "    def __init__(self, model, batch_size, lstm_hidden_size, idx_to_word_dict,device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.num_layers = 2\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.model = model\n",
    "        self.word_vocab_size = len(idx_to_word_dict)\n",
    "        \n",
    "    def forward(self, x, teacher_forcing_ratio=0.5):\n",
    "        \n",
    "        max_len = x.size()[0]\n",
    "        \n",
    "        hidden = torch.zeros(self.num_layers,self.batch_size,self.lstm_hidden_size)\n",
    "        cell = torch.zeros(self.num_layers,self.batch_size,self.lstm_hidden_size)\n",
    "        hiddens = (hidden,cell)\n",
    "        \n",
    "        input_ = x[0]\n",
    "        outputs = torch.zeros(max_len, batch_size, self.word_vocab_size).to(self.device)\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            # for 문이 돈다는 것은, many-to-many의 네트워크가 한 칸씩 옆으로 이동한다는 뜻과 같습니다.\n",
    "            output, hiddens = self.model(input_,hiddens)\n",
    "#            output'dimension : [batch_size , output_dim], 여기서 output_dim 은 출현 가능한 모든 target lang 의 수 입니다.\n",
    "            outputs[t] = output\n",
    "    \n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1] # 해당 글자의 numericalized index 를 넣어주어야 합니다.\n",
    "            input_ = (x[t] if teacher_force else top1)\n",
    "            \n",
    "        return outputs\n",
    "    # [sent_length, batch_size, char_vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Char_LM(model,batch_size,lstm_hidden_size,idx_to_word_dict,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([427, 3, 247632])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model(batch.text).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fit() : \n",
    "    \n",
    "    def __init__(self, model, train_iter, test_iter, epoch = 5) : \n",
    "        \n",
    "        self.optimizer = optim.Adam(model.parameters())\n",
    "        # <pad> 토큰은 임베딩 벡터와, loss_function에 argument 로 들어가서, training 과정에서 제외됩니다.\n",
    "        self.pad_idx = 1 \n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=self.pad_idx)\n",
    "        self.device = 'cpu'\n",
    "#         self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_iter = train_iter\n",
    "        self.test_iter = test_iter\n",
    "        self.epoch = epoch\n",
    "            \n",
    "    def train(self,clip):\n",
    "    \n",
    "        epoch_loss = 0 # loss per epoch\n",
    "        self.model.train()\n",
    "        \n",
    "        for i, batch in enumerate(self.train_iter):\n",
    "            print('train batch : ',i,end='\\r')\n",
    "            src = batch.text\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            output = self.model(src)        \n",
    "\n",
    "            loss_output = output[1:].view(-1, output.shape[-1])\n",
    "            loss_trg = src[1:].view(-1)\n",
    "            # sos 토큰을 제외하고, 차원을 맞춘 후에, output을 변수에 저장해줍니다.\n",
    "            \n",
    "            loss = self.criterion(loss_output, loss_trg)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            # gradient clipping\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        return epoch_loss / len(self.train_iter)\n",
    "    \n",
    "    def test(self):\n",
    "    \n",
    "        epoch_loss = 0 # loss per epoch\n",
    "        self.model.eval()\n",
    "        \n",
    "        for i, batch in enumerate(self.test_iter):\n",
    "            print('test batch : ',i,end='\\r')\n",
    "            src = batch.src\n",
    "\n",
    "            output = self.model(src)        \n",
    "\n",
    "            loss_output = output[1:].view(-1, output.shape[-1])\n",
    "            loss_trg = src[1:].view(-1)\n",
    "            # sos 토큰을 제외하고, 차원을 맞춘 후에, output을 변수에 저장해줍니다.\n",
    "            \n",
    "            loss = self.criterion(loss_output, loss_trg)\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        return epoch_loss / len(self.test_iter)\n",
    "\n",
    "    \n",
    "    \n",
    "    def fit_by_iterate(self,clip) : \n",
    "        \n",
    "        for epoch in range(self.epoch):\n",
    "            print('epoch : ',epoch + 1)\n",
    "            train_loss= self.train(clip)\n",
    "            print(\"training loss : {}\".format(train_loss))\n",
    "            \n",
    "            if epoch == self.epoch :  #마지막에 test를 실행합니다.\n",
    "                test_loss = self.test()\n",
    "                print('last test : {}'.format(test_loss))\n",
    "                \n",
    "            if (epoch % 5 == 0) and (epoch != 0): #5의 배수 epoch마다 test를 실행합니다.\n",
    "                test_loss = self.test()\n",
    "                print('testing loss : {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  1\n",
      "train batch :  0\r"
     ]
    }
   ],
   "source": [
    "fitting_process = fit(final_model,train_iter,test_iter,epoch=5)\n",
    "fitting_process.fit_by_iterate(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
